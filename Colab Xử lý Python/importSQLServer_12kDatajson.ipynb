{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "json_file_path = '12k_data_crawl.json'\n",
        "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "    json_data  = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been extracted and saved to extracted_data.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Initialize empty lists to store extracted data\n",
        "rows = []\n",
        "\n",
        "# Loop through the JSON data and extract required fields\n",
        "for item in json_data:\n",
        "    if \"annotations\" in item:\n",
        "        for annotation in item[\"annotations\"]:\n",
        "            if \"result\" in annotation:\n",
        "                luat_text = []  # Initialize empty list for \"Luật\" column\n",
        "                for result_item in annotation[\"result\"]:\n",
        "                    if \"value\" in result_item and \"text\" in result_item[\"value\"]:\n",
        "                        text_values = result_item[\"value\"][\"text\"]\n",
        "                        if text_values is not None:\n",
        "                            luat_text.extend(text_values)  # Extend the list of text values\n",
        "                row = {\n",
        "                    \"ID\": item[\"id\"],\n",
        "                    \"Tên câu hỏi\": item[\"data\"][\"short_title\"],\n",
        "                    \"Lĩnh vực\": item[\"data\"][\"linhvuc\"],\n",
        "                    \"Nội dung câu hỏi\": item[\"data\"][\"cauhoi\"],\n",
        "                    \"Câu trả lời\": item[\"data\"][\"traloi\"],\n",
        "                    \"Luật\": luat_text\n",
        "                }\n",
        "                rows.append(row)\n",
        "    else:\n",
        "        row = {\n",
        "            \"ID\": item[\"id\"],\n",
        "            \"Tên câu hỏi\": item[\"data\"][\"short_title\"],\n",
        "            \"Lĩnh vực\": item[\"data\"][\"linhvuc\"],\n",
        "            \"Nội dung câu hỏi\": item[\"data\"][\"cauhoi\"],\n",
        "            \"Câu trả lời\": item[\"data\"][\"traloi\"],\n",
        "            \"Luật\": []  # Empty list for missing annotations\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Save DataFrame to an Excel file\n",
        "excel_file_path = \"extracted_data.xlsx\"\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "print(\"Data has been extracted and saved to\", excel_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Keyphrase\n",
        "import pandas as pd\n",
        "from underthesea import word_tokenize\n",
        "from underthesea import text_normalize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyphrases for entry 1: ['Nội dung', 'câu', ':', 'Ngày', '2-3-2023', 'nộp', 'hồ sơ', 'lãnh', 'BHXH', '1', '.', 'Đến', '10-03-2023', 'kết quả', 'điện thoại', 'bảo hiểm', '.', '\"', 'BẢO HIỂM XÃ HỘI', 'TỈNH NAM ĐỊNH', 'BẢO HIỂM XÃ HỘI', 'HUYỆN NGHĨA HƯNG Số', ':', '02653', '/', '2023', '/', '03605', '/', 'TB', 'BHXH HUYỆN NGHĨA HƯNG', 'Thông báo', '1', '.', 'Chấp nhận', 'giải quyết', 'hồ sơ', 'giao dịch', 'điện tử', '/', 'tổ chức', '/', 'Số', 'hồ sơ', ':', '01630', '/', '2023', '/', '03605', '.', 'Nhận', 'hồi', ':', '15', '15', 'phút', ',', '02/03/2023', '.', 'Trả', 'kết quả', '09', '03', '2023', '.', '2', '.', 'Các', 'trường hợp', 'hồ sơ', ',', 'quy định', 'hướng dẫn', 'bổ sung', 'hồ sơ', '(', 'kèm', ')', 'Số', 'điện thoại', ':', 'Chữ ký', 'cơ quan', 'BHXH', '\"']\n",
            "Keyphrases for entry 2: ['Nội dung', 'câu', ':', 'Nhờ', 'cổng', 'trực', 'tuyến', 'tra', 'giúp', 'tham gia', 'bhxh', 'vs', '.', 'Msbh', ':', '3620762739 Số', 'CCCD', ':', '036094004273', 'Họ', ':', 'nguyễn hữu nhật']\n",
            "Keyphrases for entry 3: ['Nội dung', 'câu', ':', 'Em', 'Lê Hồng Nghi', 'sinh', '10.08.1996', '.', 'Cccd', '070196003681', ',', 'BHXH 7021996203', '.', 'Em', 'sinh', '15.1.2023', ',', 'nộp', 'đầy đủ', 'hồ sơ', 'quy định', 'bảo hiểm', 'công ty', '30.1.2023', 'tiền', 'thai sản', 'nộp', '.', 'Cho', 'hồ sơ', 'duyệt', 'chi trả', 'lao động', '.', 'Rất', 'mong', 'cơ quan', 'BHXH', 'Việt Nam', 'kiểm tra', 'trả lờ', 'giúp', '! Em', '.']\n",
            "Keyphrases for entry 4: ['Nội dung', 'câu', ':', 'Em', 'Lê Hồng Nghi', 'sinh', '10.08.1996', '.', 'Cccd', '070196003681', ',', 'BHXH 7021996203', '.', 'Em', 'sinh', '15.1.2023', ',', 'nộp', 'đầy đủ', 'hồ sơ', 'quy định', 'bảo hiểm', 'công ty', '30.1.2023', 'tiền', 'thai sản', 'nộp', '.', 'Cho', 'hồ sơ', 'duyệt', 'chi trả', 'lao động', '.', 'Rất', 'mong', 'cơ quan', 'BHXH', 'Việt Nam', 'kiểm tra', 'trả lờ', 'giúp', '! Em', '.']\n",
            "Keyphrases for entry 5: ['Nội dung', 'câu', ':', 'Kính', 'gửi', 'Quý', 'cơ quan', ',', 'Do', 'sơ suất', 'thẻ', 'BHYT', 'mẹ', 'GD4797938628508', 'Lê Thị Điểu', 'hạn', '06/10/2022', ',', 'đóng', 'tiền', 'mua', 'tiếp', '14/2/2023', 'Thời hạn', '5', 'liên tục', '30/07/2021', 'Khi', 'mua', ',', 'thẻ', 'ghi', 'hiệu lực', '15/3/2023', 'Vậy', 'mẹ', 'thẻ', 'BHYT', '? Và', 'hiệu lực', '15/3/2023', 'quyền lợi', '5', 'ạ Xin', 'trân trọng', 'cám ơn']\n",
            "Keyphrases for entry 6: ['Nội dung', 'câu', ':', 'Ngày', '20-02-2023', 'nộp', 'đơn', 'đề nghị', 'hưởng', 'bhxh', '1', 'huyện', 'củ Chi', 'TP', 'HCM', 'giải quyết', 'chi trả', 'lao', 'sổ', '7412177582 số', 'quyết định', '08599', '.', 'G', '/', '2023', '/', '07920']\n",
            "Keyphrases for entry 7: ['Nội dung', 'câu', ':', 'Tôi', 'Vũ Văn Thịnh', ',', 'CCCD số', '031091006985', ',', 'BHXH số', '3122722182', '.', 'Tháng', '4/2021', 'đóng', 'BHXH', 'công ty', 'H&T', ',', '6/2022', 'đóng', 'BH', 'công ty', 'GreenWork', '.', 'Cả', '2', 'công ty', 'ngang', '.', 'Giờ', 'chốt', 'bảo hiểm', '2', 'công ty', '? Và', 'chốt', '2', 'công ty', '.', 'Vì', 'sổ', 'BH', 'tờ', 'rời', 'công ty', 'Regina', 'T7', '/', '2020', '.', 'Mong', 'hồi', 'đáp', '.']\n",
            "Keyphrases for entry 8: ['Nội dung', 'câu', ':', 'Em', 'thế này', 'Hiện tại', 'thẻ', 'BHYT', 'hạn', '31-12-2022', ',', 'tốt nghiệp', 'thử', ',', 'công ty', 'chưa thể', 'mua', 'BHXH-BHYT', ',', '3', 'BHYT', 'hạn', '3', 'đóng', '.', 'Em', 'đọc', 'thông tin', 'tiền', 'BHYT', 'tự nguyện', 'hoàn trả', ',', 'doanh nghiệp', 'đóng', 'BHXH-BHYT', ',', ',', 'mua', 'BHYT', 'tự nguyện', 'doanh nghiệp', 'đóng', 'BHXH-BHYT', ',', 'tiền', 'bảo hiểm', 'tự nguyện', 'hoàn', '?']\n",
            "Keyphrases for entry 9: ['Nội dung', 'câu', ':', 'Chào', 'anh chị', '! Em', 'thắc mắc', 'sổ', 'bhxh', 'chốt', '?', 'Mã số', '8923680520', '.', 'Em', 'liên hệ', 'công ty', 'cũ', 'bảo', 'chốt', 'tờ', 'rời', '.', 'Nếu', 'công ty', 'chốt', 'công ty', 'chốt', 'sổ', '? Em']\n"
          ]
        }
      ],
      "source": [
        "# Load the Excel file\n",
        "excel_file_path = \"12k_data_SQL_Okay.xlsx\"\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Load Vietnamese stopwords\n",
        "stopwords_path = \"vietnamese-stopwords.txt\"\n",
        "with open(stopwords_path, \"r\", encoding=\"utf-8\") as stopwords_file:\n",
        "    stopwords = stopwords_file.read().splitlines()\n",
        "\n",
        "# Initialize a list to store extracted keyphrases\n",
        "keyphrases = []\n",
        "\n",
        "# Extract keyphrases from the first 100 records of \"Nội dung câu hỏi\" column\n",
        "for noi_dung in df[\"Nội dung câu hỏi\"][:9]:\n",
        "    text_normalize(noi_dung)\n",
        "    words = word_tokenize(noi_dung)\n",
        "    keyphrase = [word for word in words if word not in stopwords]\n",
        "    keyphrases.append(keyphrase)\n",
        "\n",
        "# Display the extracted keyphrases\n",
        "for i, keyphrase in enumerate(keyphrases):\n",
        "    print(f\"Keyphrases for entry {i + 1}: {keyphrase}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9FTymN0sU1MM",
        "By-O7zw4Z3BR",
        "3UVSpU9sa0lI",
        "K7lmP4NxlK5E"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
